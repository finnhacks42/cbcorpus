{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc76858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tarfile\n",
    "import os.path\n",
    "\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "\n",
    "def null_safe_get_strip(dic, value):\n",
    "    \"\"\"Get an value from a dictionary and strip it.\"\"\"\n",
    "    value = dic.get(value,None)\n",
    "    if value is None:\n",
    "        return None\n",
    "    \n",
    "    if not hasattr(value, 'strip'):\n",
    "        value = ' '.join(value)\n",
    "        \n",
    "    value = value.strip()\n",
    "    if len(value) == 0:\n",
    "        return None\n",
    "    return value\n",
    "\n",
    "def null_safe_strip(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    return value.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ffd6a",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook contains code to select the files we want for each bank from all the scraped data and saves it into seperate compressed files per bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b27b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "START_YEAR = 2010 # drop any files/data from before this year.\n",
    "DATA_PATH = Path(\"~/dev/devday/data\").expanduser()\n",
    "ZIP_PATH = Path(\"~/dev/devday/data/zips\").expanduser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ce1b5",
   "metadata": {},
   "source": [
    "### RBA\n",
    "#### Bulletins\n",
    "\n",
    "Bulletins are available as html, so we can directly extract the references and abstracts without downloading pdf documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "8fb06155",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bulletin.json','r') as f:\n",
    "    rba_bul = json.load(f)\n",
    "    \n",
    "outdir = Path(ZIP_PATH)/'RBA_bulletins'\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rows = []\n",
    "ts = []\n",
    "for p in rba_bul:\n",
    "    row = {}\n",
    "    date = p['pubdate']\n",
    "    if date is None:\n",
    "        # extract it from pubtitle\n",
    "        datematch = re.search('([a-zA-Z]{3,10})\\sQuarter\\s(\\d{4})',p['pubtitle'])\n",
    "        if datematch:\n",
    "            date = datetime.strptime(f\"{datematch.group(1)}-{datematch.group(2)}\",'%B-%Y') \n",
    "        \n",
    "    row['pubdate'] = date\n",
    "    row['abstract'] = null_safe_get_strip(p,'abstract')\n",
    "    row['references'] = p.get('references',None)\n",
    "    row['has_refs'] = row['references'] is not None\n",
    "    \n",
    "    filepath = Path(p['html_path'])\n",
    "    dest = outdir/filepath.name\n",
    "    #shutil.copy(filepath, dest)\n",
    "    row['file'] = filepath.name\n",
    "\n",
    "    rows.append(row) \n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['pubdate'] = pd.to_datetime(df['pubdate'])\n",
    "df['year'] = df['pubdate'].dt.year\n",
    "\n",
    "df.to_csv(outdir/'metadata.csv')\n",
    "#make_tarfile(ZIP_PATH/'rba_bulletins.tar.gz',outdir)\n",
    "#shutil.rmtree(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "36685aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['has_refs'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5c7523",
   "metadata": {},
   "source": [
    "#### RDPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3e18fa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rdp_number', 'abstract', 'pubdate', 'authors', 'links', 'file_urls', 'files'])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('rdps.json','rb') as f:\n",
    "    rba_wp = json.load(f)\n",
    "    \n",
    "rba_wp[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "93eb5e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rdps.json','rb') as f:\n",
    "    rba_wp = json.load(f)\n",
    "    \n",
    "outdir = Path(ZIP_PATH)/'RBA_rdps'\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rows = []\n",
    "for d in rba_wp:\n",
    "    if d['pubdate'] is not None:\n",
    "        pubdate = d['pubdate'].strip()\n",
    "        date = re.search('[a-z]{3,9} \\d{4}',pubdate)\n",
    "        if date:\n",
    "            s,e = date.span()\n",
    "            pubdate = datetime.strptime(pubdate[s-1:e],'%B %Y')\n",
    "            nfiles = len(d['files'])\n",
    "            filename = None\n",
    "            if nfiles == 1:\n",
    "                filepath = Path((d['files'][0])['path'])\n",
    "                filename = filepath.name\n",
    "                src = DATA_PATH/filepath\n",
    "                dest = outdir/filename\n",
    "                shutil.copy(src,dest)\n",
    "                \n",
    "            rows.append({\n",
    "                'rdp':d['rdp_number'],\n",
    "                'abstract':d['abstract'],\n",
    "                'date':pubdate,\n",
    "                'year':pubdate.year,\n",
    "                'authors':null_safe_strip(d['authors']),\n",
    "                'nfiles':nfiles,\n",
    "                'file':filename,\n",
    "            })\n",
    "            \n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(outdir/'metadata.csv')\n",
    "make_tarfile(ZIP_PATH/'rba_rdp.tar.gz',outdir)\n",
    "shutil.rmtree(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da3d6de",
   "metadata": {},
   "source": [
    "### BOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2276f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('papers.json','rb') as f:\n",
    "    boe_wp = json.load(f)\n",
    "\n",
    "outdir = Path(ZIP_PATH)/'boe_rdps'\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rows = []\n",
    "for p in boe_wp:\n",
    "    row = {}\n",
    "    datematch = re.search(\"\\d{2} [a-zA-Z]{3,10} \\d{4}\",p['pubdate'])\n",
    "    row['pubdate'] = datetime.strptime(datematch.group(),'%d %B %Y')\n",
    "    row['abstract'] = null_safe_get_strip(p,'abstract')\n",
    "    row['year'] = row['pubdate'].year\n",
    "    \n",
    "    filename = None\n",
    "    if len(p['files']) == 1:\n",
    "        filepath = Path(p['files'][0]['path'])\n",
    "        filename = filepath.name\n",
    "        src = DATA_PATH/filepath\n",
    "        dest = outdir/filename\n",
    "        #shutil.copy(src,dest)\n",
    "    row['file'] = filename\n",
    "    \n",
    "    if row['year'] > START_YEAR:\n",
    "        rows.append(row)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(rows)  \n",
    "df['year'] = df['pubdate'].dt.year\n",
    "df['has_abstract'] = df['abstract'].notnull()\n",
    "df.to_csv(outdir/'metadata.csv')\n",
    "make_tarfile(ZIP_PATH/'boe_rdps.tar.gz',outdir)\n",
    "shutil.rmtree(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9abdaa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no per file metadata here - just all files by year.\n",
    "with open('boe_bull2.json','rb') as f:\n",
    "    boe_bul = json.load(f) \n",
    "\n",
    "outdir = outdir = Path(ZIP_PATH)/'boe_bulletins'\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "rows = []\n",
    "for year_data in boe_bul:\n",
    "    year = year_data['year']\n",
    "    if int(year) > START_YEAR:\n",
    "        for file in year_data['files']:\n",
    "            row = {'year':year}\n",
    "            src = DATA_PATH/file['path']\n",
    "            dest = outdir/src.name\n",
    "            shutil.copy(src,dest)\n",
    "            row['file'] = src.name\n",
    "            rows.append(row)\n",
    "            \n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(outdir/'metadata.csv')\n",
    "make_tarfile(ZIP_PATH/'boe_bulletins.tar.gz',outdir)\n",
    "shutil.rmtree(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbcb018",
   "metadata": {},
   "source": [
    "### Fed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3207e6",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "- content is available as html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c065bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the fed notes - full note available as html\n",
    "\n",
    "outdir = Path(ZIP_PATH)/'fed_notes'\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "with open('fed_notes_meta.json','r') as f:\n",
    "    data = json.load(f)\n",
    "rows = []\n",
    "for d in data:\n",
    "    date = pd.to_datetime(d['pubdate'])\n",
    "    \n",
    "    row = {}\n",
    "    row['title'] = d['title']\n",
    "    row['pubdate'] = d['pubdate']\n",
    "    row['references'] = d.get('references',None)\n",
    "    row['summary'] = null_safe_get_strip(d,'summary')\n",
    "    htmlpath = Path(d['html_path'])\n",
    "    row['file'] = htmlpath.name\n",
    "    dest = outdir/htmlpath.name\n",
    "    shutil.copy(htmlpath,dest)\n",
    "    rows.append(row)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(rows)\n",
    "df['pubdate'] = pd.to_datetime(df['pubdate'])\n",
    "df['year'] = df['pubdate'].dt.year\n",
    "df.to_csv(outdir/'metadata.csv')\n",
    "\n",
    "make_tarfile(ZIP_PATH/'fed_notes.tar.gz',outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c49b1a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "635c5acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-01-04 00:00:00')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(d['pubdate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b91f90",
   "metadata": {},
   "source": [
    "#### FEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23f6e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path(ZIP_PATH)/'fed_feds'\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open('feds2.json','rb') as f:\n",
    "    fed_wp = json.load(f)\n",
    "\n",
    "rows = []\n",
    "for p in fed_wp:\n",
    "    date = datetime.strptime(p['pubdate'],'%B %Y')\n",
    "    if date.year >= START_YEAR:\n",
    "        row = {}\n",
    "        row['pubdate'] = date\n",
    "        row['year'] = date.year\n",
    "        row['title'] = null_safe_get_strip(p,'title')\n",
    "        filepath = p['files'][0]['path']\n",
    "        filename = Path(filepath).name\n",
    "        row['file'] = filename\n",
    "        \n",
    "        src = DATA_PATH/filepath\n",
    "        dest = outdir/filename\n",
    "        \n",
    "        shutil.copy(src,dest)\n",
    "\n",
    "    rows.append(row)\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(outdir/'metadata.csv')\n",
    "\n",
    "make_tarfile(ZIP_PATH/'fed_feds.tar.gz',outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccdad474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.federalreserve.gov/pubs/feds/2014/201418/201418pap.pdf',\n",
       "  'path': 'full/3a77991d769b316e2d28f430e505cce24f0c1970.pdf',\n",
       "  'checksum': 'b34e45814c411426f57b217530d39769',\n",
       "  'status': 'downloaded'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3962c930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfiles\n",
       "1    1759\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('nfiles').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8909aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubdate</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>file</th>\n",
       "      <th>nfiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>Small Price Responses to Large Demand Shocks</td>\n",
       "      <td>3a77991d769b316e2d28f430e505cce24f0c1970.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>Finance and Productivity Growth: Firm-level Ev...</td>\n",
       "      <td>3fa79c4dde27327dde29fdeef8ed579a3dad98eb.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>Using Data on Seller Behavior to Forecast Shor...</td>\n",
       "      <td>5d012ea2cb9f4e8a8b19bee878d0f646dcb6509e.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>Banks as Patient Fixed Income Investors</td>\n",
       "      <td>995f4b0c60cb6c6a76901899c9075a5b7fd253d8.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>The Interplay Between Student Loans and Credit...</td>\n",
       "      <td>b6124a03eabcc81b7279f703f05f03d595fb94cc.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pubdate  year                                              title  \\\n",
       "0 2014-03-01  2014       Small Price Responses to Large Demand Shocks   \n",
       "1 2014-03-01  2014  Finance and Productivity Growth: Firm-level Ev...   \n",
       "2 2014-02-01  2014  Using Data on Seller Behavior to Forecast Shor...   \n",
       "3 2014-02-01  2014            Banks as Patient Fixed Income Investors   \n",
       "4 2014-02-01  2014  The Interplay Between Student Loans and Credit...   \n",
       "\n",
       "                                           file  nfiles  \n",
       "0  3a77991d769b316e2d28f430e505cce24f0c1970.pdf       1  \n",
       "1  3fa79c4dde27327dde29fdeef8ed579a3dad98eb.pdf       1  \n",
       "2  5d012ea2cb9f4e8a8b19bee878d0f646dcb6509e.pdf       1  \n",
       "3  995f4b0c60cb6c6a76901899c9075a5b7fd253d8.pdf       1  \n",
       "4  b6124a03eabcc81b7279f703f05f03d595fb94cc.pdf       1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81fefff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfiles\n",
       "0    1759\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('nfiles').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8c54b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content is pdfs and I seem to be missing the links!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "703f1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to work on this scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0253c1",
   "metadata": {},
   "source": [
    "### Riksbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8cdbb561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_riks_metadata_and_files(meta_json, outdirname, outzipname):\n",
    "    with open(meta_json,'rb') as f:\n",
    "        rbwp = json.load(f)\n",
    "    outdir = Path(ZIP_PATH)/outdirname\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    rows = []\n",
    "    for p in rbwp:\n",
    "        row = {}\n",
    "        row['pubdate'] = datetime.strptime(p['pubdate'],'%d/%m/%Y')\n",
    "        row['title'] = null_safe_get_strip(p, 'title')\n",
    "        filename = None\n",
    "        if len(p['files']) == 1:\n",
    "            file = p['files'][0]\n",
    "            filepath = Path(file['path'])\n",
    "            filename = filepath.name\n",
    "            src = DATA_PATH/filepath\n",
    "            dest = outdir/filename\n",
    "            shutil.copy(src,dest)  \n",
    "        row['file'] = filename\n",
    "        row['url'] = p['pdf_url']\n",
    "        row['has_file'] = filename is not None\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['year'] = df['pubdate'].dt.year   \n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(outdir/'metadata.csv')\n",
    "    make_tarfile(ZIP_PATH/outzipname,outdir)\n",
    "    shutil.rmtree(outdir)\n",
    "    return df\n",
    "    \n",
    "df = extract_riks_metadata_and_files('riksbank_wp_meta.json','riksbank_wp','riks_rdp.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ea901848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_riks_metadata_and_files('riksbank_comm_meta.json','riksbank_comm','ricks_comm.tar.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
